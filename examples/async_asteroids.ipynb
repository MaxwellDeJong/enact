{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "import enact\n",
    "\n",
    "def normalize_angle(theta: np.ndarray) -> np.ndarray:\n",
    "  return (theta + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "@enact.register\n",
    "@dataclasses.dataclass\n",
    "class Action(enact.Resource):\n",
    "  array: np.ndarray = np.zeros((1, 2))\n",
    "\n",
    "  @property\n",
    "  def torque(self) -> np.ndarray:\n",
    "    print(f'ARRAY: {self.array}')\n",
    "    return self.array[..., 0]\n",
    "\n",
    "  @property\n",
    "  def thrust(self) -> np.ndarray:\n",
    "    print(f'ARRAY: {self.array}')\n",
    "    return self.array[..., 1]\n",
    "\n",
    "@enact.register\n",
    "@dataclasses.dataclass\n",
    "class State(enact.Resource):\n",
    "  \"\"\"Represents a game state.\n",
    "\n",
    "  The state is represented internally as a numpy array of length 10.\n",
    "  State components can be accessed with setters and getters:\n",
    "  * Agent position\n",
    "  * Agent orientation [-pi, pi]\n",
    "  * Agent velocity\n",
    "  * Agent angular speed\n",
    "  * Goal position\n",
    "  * Has been at goal\n",
    "\n",
    "  A state object may represent an arbitrary batch of states.\n",
    "  \"\"\"\n",
    "\n",
    "  # Indices and slices into the underlying arrays.\n",
    "  POSITION_SLICE = slice(0, 2)\n",
    "  ROTATION_INDEX = 2\n",
    "  VELOCITY_SLICE = slice(3, 5)\n",
    "  ANGULAR_VELOCITY_INDEX = 5\n",
    "  GOAL1_POSITION_SLICE = slice(6, 8)\n",
    "  HAS_BEEN_AT_GOAL1_INDEX = 8\n",
    "  GOAL2_POSITION_SLICE = slice(9, 11)\n",
    "  HAS_BEEN_AT_GOAL2_INDEX = 11\n",
    "  # Total dimensionality of the state space array.\n",
    "  ARRAY_SIZE = 12\n",
    "\n",
    "  # Game configuration.\n",
    "  BOARD_SIZE = 25\n",
    "  REACHED_EPSILON = 1\n",
    "  TORQUE_FORCE = 0.5\n",
    "  THRUST_FORCE = 0.5\n",
    "  MAX_SPEED = 2\n",
    "  FRICTION_COEFFICIENT = 0.99\n",
    "\n",
    "  array: np.ndarray = np.zeros((1, ARRAY_SIZE))\n",
    "\n",
    "  def randomize(self):\n",
    "    batch_shape = self.array.shape[:-1]\n",
    "    self.position = np.random.uniform(0, State.BOARD_SIZE, batch_shape + (2,))\n",
    "    self.rotation = np.random.uniform(-np.pi, np.pi, batch_shape)\n",
    "    self.goal1_position = np.random.uniform(\n",
    "      0, State.BOARD_SIZE, batch_shape + (2,))\n",
    "    self.goal2_position = np.random.uniform(\n",
    "      0, State.BOARD_SIZE, batch_shape + (2,))\n",
    "    self.success = np.zeros_like(self.rotation)\n",
    "\n",
    "  @property\n",
    "  def position(self) -> np.ndarray:\n",
    "    \"\"\"Return the position of the agent.\"\"\"\n",
    "    return self.array[..., State.POSITION_SLICE]\n",
    "\n",
    "  @position.setter\n",
    "  def position(self, value: np.ndarray):\n",
    "    \"\"\"Set the position of the agent.\"\"\"\n",
    "    self.array[..., State.POSITION_SLICE] = value\n",
    "\n",
    "  @property\n",
    "  def rotation(self) -> np.ndarray:\n",
    "    \"\"\"Return the rotation of the agent. Positive is counter-clockwise.\"\"\"\n",
    "    return self.array[..., State.ROTATION_INDEX]\n",
    "\n",
    "  @rotation.setter\n",
    "  def rotation(self, value: np.ndarray):\n",
    "    \"\"\"Set the rotation of the agent (normalized to [-pi, pi]).\"\"\"\n",
    "    self.array[..., State.ROTATION_INDEX] = normalize_angle(value)\n",
    "\n",
    "  @property\n",
    "  def velocity(self) -> np.ndarray:\n",
    "    \"\"\"Two dimensional velocity vector of the agent.\"\"\"\n",
    "    return self.array[..., State.VELOCITY_SLICE]\n",
    "\n",
    "  @velocity.setter\n",
    "  def velocity(self, value: np.ndarray):\n",
    "    \"\"\"Set the velocity.\"\"\"\n",
    "    self.array[..., State.VELOCITY_SLICE] = value\n",
    "\n",
    "  @property\n",
    "  def angular_velocity(self) -> np.ndarray:\n",
    "    \"\"\"The angular velocity of the agent.\"\"\"\n",
    "    return self.array[..., State.ANGULAR_VELOCITY_INDEX]\n",
    "\n",
    "  @angular_velocity.setter\n",
    "  def angular_velocity(self, value: np.ndarray):\n",
    "    \"\"\"Set the angular velocity of the agent.\"\"\"\n",
    "    self.array[..., State.ANGULAR_VELOCITY_INDEX] = value\n",
    "\n",
    "  @property\n",
    "  def goal1_position(self) -> np.ndarray:\n",
    "    \"\"\"The position of the goal.\"\"\"\n",
    "    return self.array[..., State.GOAL1_POSITION_SLICE]\n",
    "\n",
    "  @goal1_position.setter\n",
    "  def goal1_position(self, value: np.ndarray):\n",
    "    \"\"\"Set the position of the goal.\"\"\"\n",
    "    self.array[..., State.GOAL1_POSITION_SLICE] = value\n",
    "\n",
    "  @property\n",
    "  def has_been_at_goal1(self) -> np.ndarray:\n",
    "    \"\"\"Whether the agent has been at the goal.\"\"\"\n",
    "    return self.array[..., State.HAS_BEEN_AT_GOAL1_INDEX]\n",
    "\n",
    "  @has_been_at_goal1.setter\n",
    "  def has_been_at_goal1(self, value: np.ndarray):\n",
    "    \"\"\"Set whether the agent has been at the goal.\"\"\"\n",
    "    self.array[..., State.HAS_BEEN_AT_GOAL1_INDEX] = value\n",
    "\n",
    "  @property\n",
    "  def goal2_position(self) -> np.ndarray:\n",
    "    \"\"\"The position of the goal.\"\"\"\n",
    "    return self.array[..., State.GOAL2_POSITION_SLICE]\n",
    "\n",
    "  @goal2_position.setter\n",
    "  def goal2_position(self, value: np.ndarray):\n",
    "    \"\"\"Set the position of the goal.\"\"\"\n",
    "    self.array[..., State.GOAL2_POSITION_SLICE] = value\n",
    "\n",
    "  @property\n",
    "  def has_been_at_goal2(self) -> np.ndarray:\n",
    "    \"\"\"Whether the agent has been at the goal.\"\"\"\n",
    "    return self.array[..., State.HAS_BEEN_AT_GOAL2_INDEX]\n",
    "\n",
    "  @has_been_at_goal2.setter\n",
    "  def has_been_at_goal2(self, value: np.ndarray):\n",
    "    \"\"\"Set whether the agent has been at the goal.\"\"\"\n",
    "    self.array[..., State.HAS_BEEN_AT_GOAL2_INDEX] = value\n",
    "\n",
    "  def forward(self, offset: float=0) -> np.ndarray:\n",
    "    \"\"\"The unit vector pointing forward relative to the agent.\"\"\"\n",
    "    return np.stack([np.cos(self.rotation + offset),\n",
    "                     np.sin(self.rotation + offset)], axis=-1)\n",
    "\n",
    "  def right(self, offset: float=0) -> np.ndarray:\n",
    "    \"\"\"The unit vector pointing right relative to the agent.\"\"\"\n",
    "    return self.forward(offset - np.pi / 2)\n",
    "\n",
    "  def at_goal1(self) -> np.ndarray:\n",
    "    \"\"\"Whether the agent is currently at the goal.\"\"\"\n",
    "    return np.linalg.norm(\n",
    "      self.position - self.goal1_position, axis=-1) < State.REACHED_EPSILON\n",
    "\n",
    "  def at_goal2(self) -> np.ndarray:\n",
    "    \"\"\"Whether the agent is currently at the goal.\"\"\"\n",
    "    return np.linalg.norm(\n",
    "      self.position - self.goal2_position, axis=-1) < State.REACHED_EPSILON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import contextlib\n",
    "import dataclasses\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class AsyncPolicy(abc.ABC):\n",
    "  @abc.abstractmethod\n",
    "  async def compute_actions(self, observations: State) -> State:\n",
    "    \"\"\"Compute actions from observations.\"\"\"\n",
    "  \n",
    "  @abc.abstractmethod\n",
    "  async def stop(self):\n",
    "    \"\"\"Stop the policy.\"\"\"\n",
    "  \n",
    "\n",
    "class Game:\n",
    "  def __init__(self, policy: AsyncPolicy):\n",
    "    self.policy = policy\n",
    "    self.state = State()\n",
    "    self.state.randomize()\n",
    "    self.steps = 300\n",
    "\n",
    "  async def dynamics(self, actions: Action) -> State:\n",
    "    dt = 0.1\n",
    "    next_state = State(np.copy(self.state.array))\n",
    "    # Update velocity by applying acceleration forces.\n",
    "    thrust = np.clip(actions.thrust, 0, 1)\n",
    "    torque = np.clip(actions.torque, -1, 1)\n",
    "    next_state.velocity += (\n",
    "        dt * self.state.THRUST_FORCE *\n",
    "        self.state.forward() * np.expand_dims(thrust, axis=-1))\n",
    "    next_state.angular_velocity += dt * self.state.TORQUE_FORCE * torque\n",
    "\n",
    "    # Clamp max speed and apply friction.\n",
    "    speed = np.clip(\n",
    "        np.expand_dims(np.linalg.norm(next_state.velocity, axis=-1), -1),\n",
    "        1e-10, np.infty)\n",
    "\n",
    "    at_maxed_out_speed = (next_state.velocity / speed) * self.state.MAX_SPEED\n",
    "    next_state.velocity = np.where(\n",
    "        speed > self.state.MAX_SPEED, at_maxed_out_speed, next_state.velocity)\n",
    "\n",
    "    next_state.velocity *= self.state.FRICTION_COEFFICIENT\n",
    "    next_state.angular_velocity *= self.state.FRICTION_COEFFICIENT\n",
    "\n",
    "    # Update position by applying velocity.\n",
    "    next_state.position += dt * next_state.velocity\n",
    "    next_state.rotation += dt * next_state.angular_velocity\n",
    "\n",
    "    next_state.has_been_at_goal1 += next_state.at_goal1()\n",
    "    next_state.has_been_at_goal1 = np.clip(next_state.has_been_at_goal1, 0, 1)\n",
    "\n",
    "    next_state.has_been_at_goal2 += next_state.at_goal2()\n",
    "    next_state.has_been_at_goal2 = np.clip(next_state.has_been_at_goal2, 0, 1)\n",
    "\n",
    "    return next_state\n",
    "  \n",
    "  async def update(self):\n",
    "    print('Performing game update.')\n",
    "    actions = await self.policy.compute_actions(self.state)\n",
    "    print('Received actions.')\n",
    "    self.state = await self.dynamics(actions)\n",
    "    print('Received state.')\n",
    "    print('Finished game update.')\n",
    "  \n",
    "  async def game_loop(self):\n",
    "    for i in range(self.steps):\n",
    "      print(f'Starting game loop {i}.')\n",
    "      await self.update()\n",
    "    await self.policy.stop()\n",
    "  \n",
    "\n",
    "@enact.typed_invokable(Action, enact.NPArray)\n",
    "class Step(enact.Invokable):\n",
    "  def call(self, action: Action) -> enact.NPArray:\n",
    "    api = PolicyAPI.current()\n",
    "    return api.state.array\n",
    "\n",
    "\n",
    "@enact.contexts.register\n",
    "@enact.typed_invokable(enact.NoneResource, enact.NoneResource)\n",
    "@dataclasses.dataclass\n",
    "class PolicyAPI(enact.AsyncInvokable, enact.contexts.Context):\n",
    "  \"\"\"Runs a policy and exposes an API to the game.\"\"\"\n",
    "  policy: enact.AsyncInvokable\n",
    "  record_step: Step = dataclasses.field(default_factory=Step)\n",
    "\n",
    "  def __post_init__(self):\n",
    "    enact.contexts.Context.__init__(self)\n",
    "    self.started = asyncio.Event()\n",
    "    self.has_observation = asyncio.Event()\n",
    "    self.has_action = asyncio.Event()\n",
    "    self.is_done = asyncio.Event()\n",
    "    self.game: Optional[Game] = None\n",
    "    self.action: Optional[float] = None\n",
    "  \n",
    "  @contextlib.contextmanager\n",
    "  def connect_to(self, game: Game):\n",
    "    self.game = game\n",
    "    with self:\n",
    "      try:\n",
    "        yield\n",
    "      finally:\n",
    "        self.game = None\n",
    "\n",
    "  @property\n",
    "  def state(self) -> State:\n",
    "    return self.game.state\n",
    "\n",
    "  async def stop(self):\n",
    "    \"\"\"Stop the policy.\"\"\"\n",
    "    self.is_done.set()\n",
    "  \n",
    "  async def compute_actions(self, observations: State) -> Action:\n",
    "    print('Beginning compute actions')\n",
    "    await asyncio.wait_for(self.started.wait(), timeout=1.0)\n",
    "    print('Received observation.')\n",
    "    self.has_observation.set()\n",
    "    await self.has_action.wait()\n",
    "    print('Received action.')\n",
    "    self.has_action.clear()\n",
    "    assert self.action is not None\n",
    "    return self.action\n",
    "\n",
    "  async def init(self):\n",
    "    self.started.set()\n",
    "    await asyncio.wait_for(self.has_observation.wait(), timeout=1.0)\n",
    "\n",
    "  async def step(self, action: Action):\n",
    "    print('Starting policy step.')\n",
    "    self.record_step(action)\n",
    "    self.action = action\n",
    "    self.has_action.set()\n",
    "    print('Waiting for observation.')\n",
    "    await self.has_observation.wait()\n",
    "    self.has_observation.clear()\n",
    "    print('Finished policy step.')\n",
    "    \n",
    "  async def call(self):\n",
    "    await self.init()\n",
    "    policy_task = asyncio.create_task(self.policy())\n",
    "    done, _ = await asyncio.wait(\n",
    "      [policy_task, self.is_done.wait()],\n",
    "      return_when=asyncio.FIRST_COMPLETED)\n",
    "    if policy_task in done and not len(done) == 2:\n",
    "      raise ValueError('Policy completed before game.')\n",
    "    policy_task.cancel()\n",
    "    try:\n",
    "      await policy_task\n",
    "    except asyncio.CancelledError:\n",
    "      pass\n",
    "\n",
    "\n",
    "@enact.typed_invokable(enact.NoneResource, PolicyAPI)\n",
    "class CoroutinePolicy(enact.AsyncInvokable):\n",
    "  def api(self) -> PolicyAPI:\n",
    "    return PolicyAPI.current()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@enact.register\n",
    "#@dataclasses.dataclass\n",
    "@enact.typed_invokable(enact.NoneResource, enact.NoneResource)\n",
    "class AimAt(CoroutinePolicy):\n",
    "  \n",
    "  async def call(self):\n",
    "    while True:\n",
    "      print('Calling AimAt.')\n",
    "      api = self.api()\n",
    "      thrust = np.random.uniform(0, 1)\n",
    "      torque = np.random.uniform(-1, 1)\n",
    "      print('Awaiting API step...')\n",
    "      await api.step(Action(np.array([[thrust, torque]])))\n",
    "\n",
    "\n",
    "@enact.typed_invokable(enact.NoneResource, enact.NoneResource)\n",
    "class ChangeAim(CoroutinePolicy):\n",
    "\n",
    "  async def call(self):\n",
    "    print('Calling ChangeAim.')\n",
    "    counter = 0\n",
    "    while True:\n",
    "      print(f'Counter: {counter}')\n",
    "      counter += 1\n",
    "      target = np.random.uniform(0, 25, ((1, 2)))\n",
    "      aim_at = AimAt(target)\n",
    "      await aim_at()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting game loop 0.\n",
      "Performing game update.\n",
      "Beginning compute actions\n",
      "Received observation.\n",
      "Calling AimAt.\n",
      "Awaiting API step...\n",
      "Starting policy step.\n"
     ]
    }
   ],
   "source": [
    "#api = PolicyAPI(ChangeAim())\n",
    "api = PolicyAPI(AimAt())\n",
    "game = Game(api)\n",
    "with enact.InMemoryStore() as store:\n",
    "  with api.connect_to(game):\n",
    "    invocation, _ = await asyncio.gather(api.invoke(), game.game_loop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AimAt' object has no attribute 'target_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39myield from\u001b[39;00m get_observations(c, aim_target)\n\u001b[1;32m     12\u001b[0m \u001b[39mwith\u001b[39;00m store:\n\u001b[0;32m---> 13\u001b[0m   observations \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39;49m(get_observations(invocation)))\n\u001b[1;32m     14\u001b[0m   positions \u001b[39m=\u001b[39m observations[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m   targets \u001b[39m=\u001b[39m observations[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mget_observations\u001b[0;34m(i, aim_target)\u001b[0m\n\u001b[1;32m      8\u001b[0m   aim_target \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mrequest()\u001b[39m.\u001b[39minvokable()\u001b[39m.\u001b[39mtarget_position\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m i\u001b[39m.\u001b[39mget_children():\n\u001b[0;32m---> 10\u001b[0m   \u001b[39myield from\u001b[39;00m get_observations(c, aim_target)\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mget_observations\u001b[0;34m(i, aim_target)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[39myield\u001b[39;00m [\u001b[39m*\u001b[39mi\u001b[39m.\u001b[39mresponse()\u001b[39m.\u001b[39moutput(), aim_target]\n\u001b[1;32m      7\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(i\u001b[39m.\u001b[39mrequest()\u001b[39m.\u001b[39minvokable(), AimAt):\n\u001b[0;32m----> 8\u001b[0m   aim_target \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39;49mrequest()\u001b[39m.\u001b[39;49minvokable()\u001b[39m.\u001b[39;49mtarget_position\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m i\u001b[39m.\u001b[39mget_children():\n\u001b[1;32m     10\u001b[0m   \u001b[39myield from\u001b[39;00m get_observations(c, aim_target)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AimAt' object has no attribute 'target_position'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_observations(i: enact.Invocation, aim_target: float=0.0):\n",
    "  if isinstance(i.request().invokable(), Step):\n",
    "    yield [*i.response().output(), aim_target]\n",
    "  elif isinstance(i.request().invokable(), AimAt):\n",
    "    aim_target = i.request().invokable().target_position\n",
    "  for c in i.get_children():\n",
    "    yield from get_observations(c, aim_target)\n",
    "\n",
    "with store:\n",
    "  observations = np.array(list(get_observations(invocation)))\n",
    "  positions = observations[:, 0]\n",
    "  targets = observations[:, -1]\n",
    "  plt.plot(targets, alpha=0.4)\n",
    "  plt.plot(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
